{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13437fd3",
   "metadata": {},
   "source": [
    "This project is about to classify either a movie rating is positive or negative depending on text review. The dataset contain about 6000 movie rating, 3000 thousand of which is positive & 3000 of which is negative. There are several reviews with NaN value. For this project two Machine learning algorithm will be performed.\n",
    "1. Support Vector Machine (SVM)\n",
    "2. GradientBoostingClassifier\n",
    "\n",
    "The dataset is taken from http://ai.stanford.edu/~amaas/data/sentiment/ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cf077c",
   "metadata": {},
   "source": [
    "### Movie Rating Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a847f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing requried library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# to split dataset into train & test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To build a pipeline & vectorization\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# To build the model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# To measure the accuracy\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ceea9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>I loved this movie and will watch it again. Or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>A warm, touching movie that has a fantasy-like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>I was not expecting the powerful filmmaking ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>This so-called \"documentary\" tries to tell tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>This show has been my escape from reality for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   pos  I loved this movie and will watch it again. Or...\n",
       "1   pos  A warm, touching movie that has a fantasy-like...\n",
       "2   pos  I was not expecting the powerful filmmaking ex...\n",
       "3   neg  This so-called \"documentary\" tries to tell tha...\n",
       "4   pos  This show has been my escape from reality for ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading dataset\n",
    "df = pd.read_csv('moviereviews2.tsv', sep='\\t')\n",
    "df.head() # view top 5 rows of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c576389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    3000\n",
       "pos    3000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's see how many postive and negative reviews are there\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c27d3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label      0\n",
      "review    20\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking if is there any null\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b0450e",
   "metadata": {},
   "source": [
    "There are 20 null values in review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcf57cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "# If there are any duplicate value in review\n",
    "print(df.review.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3705c2",
   "metadata": {},
   "source": [
    "There are 33 same review appears in the dataset. \n",
    "\n",
    "Now let's remove the null values & also the duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f055a9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6db576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label     0\n",
      "review    0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check again for the null and duplicates\n",
    "print(df.isnull().sum())\n",
    "print(df.review.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6410fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's check if there is only space in any review\n",
    "space = []\n",
    "\n",
    "for idx, lb, rv in df.itertuples():\n",
    "    if rv.isspace():\n",
    "        space.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "551a5217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a1347f",
   "metadata": {},
   "source": [
    "There is no review having only space.\n",
    "\n",
    "Now let's split the dataset into train & test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e811b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['label'], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a402e033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's vectorize the data for the ml model\n",
    "tfidf = TfidfVectorizer() # creating instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60bc2bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfid = tfidf.fit_transform(X_train) # fit transform train data\n",
    "X_test_tfid = tfidf.transform(X_test) # transform test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc322e",
   "metadata": {},
   "source": [
    "Now let's build the model\n",
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67d8a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_ = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46cea291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_.fit(X_train_tfid, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "994932ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "pred_svc = svc_.predict(X_test_tfid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "741bac9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9349865951742627\n"
     ]
    }
   ],
   "source": [
    "# let's evaluate the model\n",
    "print(metrics.accuracy_score(y_test, pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b98dd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[702  47]\n",
      " [ 50 693]]\n",
      "============================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.94      0.93      0.93       743\n",
      "         pos       0.93      0.94      0.94       749\n",
      "\n",
      "    accuracy                           0.93      1492\n",
      "   macro avg       0.93      0.93      0.93      1492\n",
      "weighted avg       0.93      0.93      0.93      1492\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the model has an accuracy of 94%.\n",
    "# let's see the confusion matrix and classification report\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, pred_svc, labels=['pos','neg']))\n",
    "print('============================================')\n",
    "print(metrics.classification_report(y_test, pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e282660",
   "metadata": {},
   "source": [
    "Here we can see that the model perform very well. It predicted 47 review positive where it meant to be negative and 50 negative where it ment to be positive. It's precision & recall values are also quite good. \n",
    "\n",
    "Let's move to second algorithm.\n",
    "\n",
    "##### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cf95dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier() # creating instance with all default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b784e903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.fit(X_train_tfid, y_train) # fitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a24721de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on test data\n",
    "\n",
    "pred_gbc = gbc.predict(X_test_tfid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e799054d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9349865951742627\n"
     ]
    }
   ],
   "source": [
    "# checking the model performance\n",
    "print(metrics.accuracy_score(y_test, pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c636b607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[685  64]\n",
      " [139 604]]\n",
      "============================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.90      0.81      0.86       743\n",
      "         pos       0.83      0.91      0.87       749\n",
      "\n",
      "    accuracy                           0.86      1492\n",
      "   macro avg       0.87      0.86      0.86      1492\n",
      "weighted avg       0.87      0.86      0.86      1492\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the model has an accuracy of 93%.\n",
    "# let's see the confusion matrix and classification report\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, pred_gbc, labels=['pos','neg']))\n",
    "print('============================================')\n",
    "print(metrics.classification_report(y_test, pred_gbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc749ad",
   "metadata": {},
   "source": [
    "The GradientBoosing perform worst than the SVC. So for final we'll consider the SVC model. \n",
    "\n",
    "NOw let's create a pipeline for the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62761708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating pipeline\n",
    "text_clf = Pipeline([('tfidf',TfidfVectorizer()),\n",
    "                    ('clf',LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5728c36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the raw data into the pipeline\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c890c5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "pred = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "799f3b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[693  50]\n",
      " [ 47 702]]\n",
      "==========================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.94      0.93      0.93       743\n",
      "         pos       0.93      0.94      0.94       749\n",
      "\n",
      "    accuracy                           0.93      1492\n",
      "   macro avg       0.93      0.93      0.93      1492\n",
      "weighted avg       0.93      0.93      0.93      1492\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "print('==========================')\n",
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a71f509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9349865951742627\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e34cb19",
   "metadata": {},
   "source": [
    "The final model performs 94% accuracy with an f-1 score of 0.93 & 0.94 which is quite good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bf0523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
